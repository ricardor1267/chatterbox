# ğŸ¯ GUÃA RÃPIDA - Worker de Chatterbox para RunPod

## âœ… Lo Que Se Ha Creado

He creado un worker completo y optimizado para RunPod siguiendo el tutorial oficial:

### Archivos Creados

```
chatterbox/
â”œâ”€â”€ rp_handler.py          âœ… Handler principal con cachÃ© de modelos
â”œâ”€â”€ Dockerfile             âœ… Imagen Docker optimizada
â”œâ”€â”€ test_input.json        âœ… Input de prueba
â”œâ”€â”€ build_worker.sh        âœ… Script de construcciÃ³n
â”œâ”€â”€ test_worker.py         âœ… Script de tests locales
â”œâ”€â”€ WORKER_README.md       âœ… DocumentaciÃ³n completa
â””â”€â”€ QUICK_START.md         âœ… Esta guÃ­a
```

### CaracterÃ­sticas del Worker

âœ… **CachÃ© de modelos** - Los modelos se cargan una vez y se reutilizan  
âœ… **Manejo de errores** - ValidaciÃ³n completa y mensajes claros  
âœ… **23 idiomas** - Soporte multilingÃ¼e completo  
âœ… **ClonaciÃ³n de voz** - Zero-shot voice cloning  
âœ… **Logs detallados** - FÃ¡cil debugging  
âœ… **Pre-carga de modelos** - Dockerfile descarga modelos en build time  

---

## ğŸš€ OPCIÃ“N 1: Prueba Local (Recomendado)

Antes de desplegar, prueba localmente:

### Paso 1: Instalar Dependencias

```bash
cd /Users/mimac/mining/testApi/git/chatterbox

# Instalar RunPod SDK
pip install runpod
```

### Paso 2: Probar el Handler

```bash
# Ejecutar tests
python test_worker.py

# O probar con test_input.json
python rp_handler.py
```

**Resultado esperado**:
```
ğŸš€ Starting Chatterbox TTS RunPod Worker...
ğŸ”§ Device: CUDA
====================================================================
ğŸ™ï¸  Chatterbox TTS - Processing Request
====================================================================
ğŸ“ Text: Hello! Welcome to Chatterbox...
ğŸ¤– Model: multilingual
âœ“ Using cached multilingual model
âš™ï¸  Parameters: exaggeration=0.5, cfg_weight=0.5, temp=0.8
ğŸŒ Language: en (English)
ğŸ”Š Generating audio...
ğŸ“¦ Encoding audio...
âœ“ Success! Generated 3.45s audio in 2.1s
====================================================================
```

---

## ğŸ³ OPCIÃ“N 2: Construir Docker

### Paso 1: Construir Imagen

```bash
cd /Users/mimac/mining/testApi/git/chatterbox

# Construir (reemplaza con tu usuario de Docker Hub)
./build_worker.sh ricardor1267

# O manualmente:
docker build --platform linux/amd64 \
  -t ricardor1267/chatterbox-runpod-worker:latest \
  -f Dockerfile .
```

**Tiempo estimado**: 20-40 minutos (descarga modelos)

### Paso 2: Subir a Docker Hub

```bash
# Login
docker login

# Push
docker push ricardor1267/chatterbox-runpod-worker:latest
```

**Tiempo estimado**: 10-30 minutos (dependiendo de tu conexiÃ³n)

---

## â˜ï¸ OPCIÃ“N 3: Desplegar en RunPod

### Paso 1: Crear Template

1. Ve a: https://runpod.io/console/serverless/user/templates
2. Click **"New Template"**
3. Configura:

```
Template Name: Chatterbox TTS Worker
Container Image: ricardor1267/chatterbox-runpod-worker:latest
Container Disk: 40 GB
Docker Command: (dejar vacÃ­o)
```

4. Click **"Save Template"**

### Paso 2: Crear Endpoint

1. Ve a: https://runpod.io/console/serverless/user/endpoints
2. Click **"New Endpoint"**
3. Configura:

```
Endpoint Name: chatterbox-tts
Template: Chatterbox TTS Worker
Active Workers: 0 (para desarrollo)
Max Workers: 3
GPUs: RTX A4000, L4, RTX 4090 (16-24GB VRAM)
FlashBoot: âœ… Enabled
```

4. Click **"Deploy"**

### Paso 3: Esperar Despliegue

- Tiempo: 5-10 minutos
- Monitorea en la pestaÃ±a "Builds"

### Paso 4: Probar

```bash
# ObtÃ©n tu ENDPOINT_ID y API_KEY del dashboard

curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/runsync \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "input": {
      "text": "Hello! Testing Chatterbox on RunPod!",
      "model_type": "english"
    }
  }'
```

---

## ğŸ“ Ejemplos de Uso

### Ejemplo 1: TTS BÃ¡sico

```bash
curl -X POST https://api.runpod.ai/v2/{ENDPOINT_ID}/runsync \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ${API_KEY}" \
  -d '{
    "input": {
      "text": "Hello world!",
      "model_type": "english"
    }
  }'
```

### Ejemplo 2: MultilingÃ¼e

```bash
# EspaÃ±ol
curl -X POST https://api.runpod.ai/v2/{ENDPOINT_ID}/runsync \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer ${API_KEY}" \
  -d '{
    "input": {
      "text": "Hola mundo!",
      "model_type": "multilingual",
      "language_id": "es"
    }
  }'
```

### Ejemplo 3: Con Python

```python
import requests
import base64

API_KEY = "tu-api-key"
ENDPOINT_ID = "tu-endpoint-id"

response = requests.post(
    f"https://api.runpod.ai/v2/{ENDPOINT_ID}/runsync",
    headers={
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    },
    json={
        "input": {
            "text": "Esto es una prueba!",
            "model_type": "multilingual",
            "language_id": "es"
        }
    }
)

result = response.json()
if "output" in result:
    audio_data = base64.b64decode(result["output"]["audio"])
    with open("output.wav", "wb") as f:
        f.write(audio_data)
    print(f"âœ“ Audio guardado! DuraciÃ³n: {result['output']['duration']}s")
```

---

## ğŸ¯ PrÃ³ximos Pasos

### Para Desarrollo

```bash
# 1. Prueba local
python test_worker.py

# 2. Modifica rp_handler.py si necesario

# 3. Vuelve a probar
python rp_handler.py
```

### Para ProducciÃ³n

```bash
# 1. Construye Docker
./build_worker.sh ricardor1267

# 2. Sube a Docker Hub
docker push ricardor1267/chatterbox-runpod-worker:latest

# 3. Despliega en RunPod
# (Sigue pasos arriba)

# 4. Configura workers activos
# Active Workers: 1+ para baja latencia
```

---

## ğŸ“Š ComparaciÃ³n: Handler Antiguo vs Nuevo

| CaracterÃ­stica | handler.py (antiguo) | rp_handler.py (nuevo) |
|----------------|---------------------|----------------------|
| CachÃ© de modelos | âŒ | âœ… |
| Logs detallados | âŒ | âœ… |
| ValidaciÃ³n robusta | BÃ¡sica | âœ… Completa |
| Manejo de errores | BÃ¡sico | âœ… Avanzado |
| Emojis en logs | âŒ | âœ… |
| MÃ©tricas de tiempo | âŒ | âœ… |
| DocumentaciÃ³n | BÃ¡sica | âœ… Completa |

---

## ğŸ”§ Diferencias Clave del Nuevo Worker

### 1. CachÃ© de Modelos
```python
# Antiguo: Cargaba modelo en cada request
MODEL_CACHE = {
    "english": None,
    "multilingual": None
}
# Nuevo: Cachea y reutiliza modelos
```

### 2. Logs Mejorados
```python
# Antiguo: print(f"Generating...")
# Nuevo:
print("=" * 60)
print("ğŸ™ï¸  Chatterbox TTS - Processing Request")
print(f"ğŸ“ Text: {text[:100]}...")
print(f"ğŸ¤– Model: {model_type}")
```

### 3. ValidaciÃ³n Completa
```python
# Valida todos los parÃ¡metros
# Mensajes de error claros
# Manejo de edge cases
```

### 4. MÃ©tricas
```python
# Retorna generation_time
# Logs de performance
# Tracking de duraciÃ³n
```

---

## ğŸ’¡ Tips y Mejores PrÃ¡cticas

### Tip 1: Prueba Local Primero
Siempre prueba localmente antes de construir Docker:
```bash
python test_worker.py
```

### Tip 2: Usa FlashBoot
Habilita FlashBoot en RunPod para cold starts mÃ¡s rÃ¡pidos

### Tip 3: Active Workers
- **Desarrollo**: 0 active workers (ahorra costos)
- **ProducciÃ³n**: 1+ active workers (baja latencia)

### Tip 4: Monitorea Costos
- Revisa el dashboard de RunPod regularmente
- Set max workers para limitar costos
- Usa /run (async) para batch jobs

### Tip 5: GPU Selection
- **MÃ­nimo**: RTX A4000 (16GB)
- **Recomendado**: RTX A5000 o L4 (24GB)
- **Ã“ptimo**: RTX 4090 (24GB)

---

## âš ï¸ Troubleshooting RÃ¡pido

### Problema: Test local falla

```bash
# SoluciÃ³n: Instala dependencias
pip install runpod chatterbox-tts
```

### Problema: Docker build lento

```
# Normal: Descarga ~10GB de modelos
# Tiempo: 20-40 minutos
# Paciencia! Solo se hace una vez
```

### Problema: Out of memory en RunPod

```
# SoluciÃ³n: Usa GPU con mÃ¡s VRAM
# Selecciona: RTX A5000, L4, o RTX 4090
```

### Problema: Cold start muy lento

```
# Soluciones:
1. âœ… Habilita FlashBoot
2. âœ… Modelos pre-descargados (ya hecho)
3. âœ… Usa 1+ active workers en producciÃ³n
```

---

## ğŸ“š DocumentaciÃ³n Completa

- **WORKER_README.md** - DocumentaciÃ³n tÃ©cnica completa
- **test_worker.py** - Tests y ejemplos
- **rp_handler.py** - CÃ³digo del handler (comentado)

---

## ğŸ‰ Â¡Listo para Empezar!

### Checklist RÃ¡pido

```
[ ] 1. Probar localmente: python test_worker.py
[ ] 2. Construir Docker: ./build_worker.sh ricardor1267
[ ] 3. Subir a Docker Hub: docker push ...
[ ] 4. Crear Template en RunPod
[ ] 5. Crear Endpoint en RunPod
[ ] 6. Probar con curl
[ ] 7. âœ… Â¡Funcionando!
```

---

## ğŸ†˜ Â¿Necesitas Ayuda?

1. **Revisa WORKER_README.md** - DocumentaciÃ³n completa
2. **Corre test_worker.py** - Debugging local
3. **Revisa logs en RunPod** - Console â†’ Endpoint â†’ Logs
4. **PregÃºntame** - Estoy aquÃ­ para ayudar

---

**Â¡Ã‰xito con tu worker de Chatterbox en RunPod! ğŸš€**
